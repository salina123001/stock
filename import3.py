import requests
import pandas as pd
import google.generativeai as genai
from dotenv import load_dotenv
import os
import random
import string
import streamlit as st
import sys

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="å°è‚¡AIåˆ†æå·¥å…·",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åœ¨ PythonAnywhere ä¸Šï¼Œæˆ‘å€‘ç›´æ¥è¨­å®šç’°å¢ƒè®Šæ•¸è€Œä¸æ˜¯ä½¿ç”¨ .env æª”æ¡ˆ
# å¦‚æœ .env æª”æ¡ˆå­˜åœ¨ï¼Œå‰‡å˜—è©¦è¼‰å…¥
try:
    load_dotenv("test.env")
except:
    pass

# å¾ç’°å¢ƒè®Šæ•¸æˆ–ç›´æ¥è¨­å®š API é‡‘é‘°
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    # å¦‚æœåœ¨ PythonAnywhere ä¸Šï¼Œä½ å¯èƒ½æƒ³è¦ç›´æ¥åœ¨é€™è£¡è¨­å®š API é‡‘é‘°
    # GEMINI_API_KEY = "ä½ çš„APIé‡‘é‘°"
    st.error("æ‰¾ä¸åˆ° Gemini API é‡‘é‘°ï¼Œè«‹ç¢ºä¿å·²è¨­å®šç’°å¢ƒè®Šæ•¸ GEMINI_API_KEY")
    st.stop()

genai.configure(api_key=GEMINI_API_KEY)

# API URLs
api_urls = {
    "roe": "https://openapi.twse.com.tw/v1/exchangeReport/BWIBBU_ALL",
    "stock_price": "https://openapi.twse.com.tw/v1/exchangeReport/STOCK_DAY_AVG_ALL",
    "finance": "https://openapi.twse.com.tw/v1/opendata/t187ap06_L_ci"
}

# éœ€è¦çš„è²¡å ±æ¬„ä½
required_columns = {
    "å…¬å¸ä»£è™Ÿ": "è‚¡ç¥¨ä»£è™Ÿ",
    "å¹´åº¦": "è²¡å ±å¹´åº¦",
    "å­£åˆ¥": "è²¡å ±å­£åº¦",
    "ç‡Ÿæ¥­æ”¶å…¥": "ç‡Ÿæ¥­é¡",
    "ç‡Ÿæ¥­æ¯›åˆ©": "ç‡Ÿæ¥­æ¯›åˆ©",
    "ç‡Ÿæ¥­åˆ©ç›Š": "ç‡Ÿæ¥­åˆ©ç›Š",
    "ç¨…å¾Œæ·¨åˆ©": "ç¨…å¾Œæ·¨åˆ©",
    "åŸºæœ¬æ¯è‚¡ç›ˆé¤˜": "EPS",
    "è‚¡æ±æ¬Šç›Šå ±é…¬ç‡": "ROE",
    "PEratio": "æœ¬ç›Šæ¯”",
    "DividendYield": "æ®–åˆ©ç‡",
    "PBratio": "è‚¡åƒ¹æ·¨å€¼æ¯”",
    "ClosingPrice": "æ”¶ç›¤åƒ¹",
    "MonthlyAveragePrice": "æœˆå‡åƒ¹"
}

@st.cache_data(ttl=3600)  # å¿«å–è³‡æ–™1å°æ™‚
def fetch_data(stock_id):
    """æ“·å–è²¡å‹™æ•¸æ“šä¸¦å­˜å…¥ DataFrame"""
    data_frames = {}

    for key in api_urls:
        try:
            response = requests.get(api_urls[key])
            if response.status_code == 200:
                df = pd.DataFrame(response.json())

                if "å…¬å¸ä»£è™Ÿ" in df.columns:
                    df.rename(columns={"å…¬å¸ä»£è™Ÿ": "è‚¡ç¥¨ä»£è™Ÿ"}, inplace=True)
                
                if "Code" in df.columns:
                    df.rename(columns={"Code": "è‚¡ç¥¨ä»£è™Ÿ"}, inplace=True)

                df.rename(columns=required_columns, inplace=True, errors='ignore')
                df = df[df["è‚¡ç¥¨ä»£è™Ÿ"].astype(str) == stock_id]

                if not df.empty:
                    data_frames[key] = df

        except Exception as e:
            st.error(f"æ“·å– {key} è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    return data_frames

def merge_data(data_frames):
    """åˆä½µè²¡å‹™æ•¸æ“š"""
    if not data_frames:
        return pd.DataFrame()

    # ç¢ºä¿ "è‚¡ç¥¨ä»£è™Ÿ" æ¬„ä½ç‚ºå­—ä¸²ï¼Œé¿å…åˆä½µå¤±æ•—
    for key in data_frames:
        if "è‚¡ç¥¨ä»£è™Ÿ" in data_frames[key].columns:
            data_frames[key]["è‚¡ç¥¨ä»£è™Ÿ"] = data_frames[key]["è‚¡ç¥¨ä»£è™Ÿ"].astype(str)

    # å¾ç¬¬ä¸€å€‹è³‡æ–™æ¡†é–‹å§‹åˆä½µ
    merged_df = next(iter(data_frames.values()))
    
    # åˆä½µå…¶é¤˜çš„è³‡æ–™æ¡†
    for key, df in data_frames.items():
        if df is not merged_df:  # é¿å…åˆä½µè‡ªå·±
            merged_df = merged_df.merge(df, on="è‚¡ç¥¨ä»£è™Ÿ", how="outer")

    # è™•ç†æ¬„ä½åç¨±é‡è¤‡å•é¡Œ
    name_columns = [col for col in merged_df.columns if col.startswith('Name')]
    if len(name_columns) > 0:
        # ä¿ç•™ç¬¬ä¸€å€‹ Name æ¬„ä½ä½œç‚ºå…¬å¸åç¨±
        merged_df.rename(columns={name_columns[0]: "å…¬å¸åç¨±"}, inplace=True)
        # åˆªé™¤å…¶ä»– Name æ¬„ä½
        for col in name_columns[1:]:
            if col in merged_df.columns:
                merged_df.drop(columns=[col], inplace=True)
    
    # å°‡æ•¸å€¼æ¬„ä½è½‰æ›ç‚ºæ•¸å€¼å‹åˆ¥ï¼ŒéŒ¯èª¤æ™‚å¡«å…… NaN
    numeric_cols = ["EPS", "ROE", "ç¨…å¾Œæ·¨åˆ©", "æœ¬ç›Šæ¯”", "æ®–åˆ©ç‡", "è‚¡åƒ¹æ·¨å€¼æ¯”", "æ”¶ç›¤åƒ¹", "æœˆå‡åƒ¹"]
    for col in numeric_cols:
        if col in merged_df.columns:
            merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce')

    return merged_df

def extract_financial_data(df, stock_id):
    """å¾åˆä½µçš„æ•¸æ“šä¸­æå–è²¡å‹™æ•¸æ“š"""
    if df.empty:
        return None

    # ç¢ºä¿è‚¡ç¥¨ä»£è™Ÿç‚ºå­—ä¸²é¡å‹
    df["è‚¡ç¥¨ä»£è™Ÿ"] = df["è‚¡ç¥¨ä»£è™Ÿ"].astype(str)
    stock_id = str(stock_id)
    
    # æª¢æŸ¥è‚¡ç¥¨æ˜¯å¦å­˜åœ¨æ–¼æ•¸æ“šä¸­
    stock_data = df[df["è‚¡ç¥¨ä»£è™Ÿ"] == stock_id]
    if stock_data.empty:
        return None

    latest_data = stock_data.iloc[-1]
    
    # å‰µå»ºä¸€å€‹ä¹¾æ·¨çš„è³‡æ–™å­—å…¸
    clean_data = {
        "è‚¡ç¥¨ä»£è™Ÿ": stock_id,
        "å…¬å¸åç¨±": latest_data.get("å…¬å¸åç¨±", "æœªçŸ¥å…¬å¸"),
        "ç‡Ÿæ¥­é¡": 0.0,
        "ç¨…å¾Œæ·¨åˆ©": 0.0,
        "EPS": 0.0,
        "ROE": 0.0,
        "æœ¬ç›Šæ¯”": 0.0,
        "æ®–åˆ©ç‡": 0.0,
        "è‚¡åƒ¹æ·¨å€¼æ¯”": 0.0,
        "æ”¶ç›¤åƒ¹": 0.0,
        "æœˆå‡åƒ¹": 0.0
    }
    
    # æ¬„ä½æ˜ å°„è¡¨
    field_mappings = {
        "ç‡Ÿæ¥­é¡": ["ç‡Ÿæ¥­é¡", "ç‡Ÿæ”¶"],
        "ç¨…å¾Œæ·¨åˆ©": ["æœ¬æœŸæ·¨åˆ©ï¼ˆæ·¨æï¼‰", "ç¨…å¾Œæ·¨åˆ©", "ç¨…å¾Œæ·¨æ", "æ·¨åˆ©"],
        "EPS": ["åŸºæœ¬æ¯è‚¡ç›ˆé¤˜ï¼ˆå…ƒï¼‰", "EPS", "æ¯è‚¡ç›ˆé¤˜"],
        "æœ¬ç›Šæ¯”": ["æœ¬ç›Šæ¯”", "P/E"],
        "æ®–åˆ©ç‡": ["æ®–åˆ©ç‡", "è‚¡åˆ©æ®–åˆ©ç‡"],
        "è‚¡åƒ¹æ·¨å€¼æ¯”": ["è‚¡åƒ¹æ·¨å€¼æ¯”", "P/B", "PBR"],
        "æ”¶ç›¤åƒ¹": ["æ”¶ç›¤åƒ¹", "è‚¡åƒ¹"],
        "æœˆå‡åƒ¹": ["æœˆå‡åƒ¹", "æœˆå¹³å‡åƒ¹"]
    }
    
    # è™•ç†æ¯å€‹æ¬„ä½
    for key, possible_cols in field_mappings.items():
        for col_name in possible_cols:
            if col_name in latest_data and pd.notna(latest_data[col_name]):
                try:
                    value = latest_data[col_name]
                    # è™•ç†å­—ä¸²æ ¼å¼çš„æ•¸å€¼
                    if isinstance(value, str):
                        value = value.replace(',', '').replace('%', '')
                    clean_data[key] = float(value)
                    break  # æ‰¾åˆ°ä¸¦æˆåŠŸè½‰æ›å¾Œè·³å‡ºå…§éƒ¨å¾ªç’°
                except (ValueError, TypeError):
                    pass
    
    # è¨ˆç®— ROE (å¦‚æœæ²’æœ‰ç›´æ¥æä¾›)
    if clean_data["ROE"] == 0:
        try:
            if clean_data["è‚¡åƒ¹æ·¨å€¼æ¯”"] > 0 and clean_data["æ”¶ç›¤åƒ¹"] > 0:
                book_value_per_share = clean_data["æ”¶ç›¤åƒ¹"] / clean_data["è‚¡åƒ¹æ·¨å€¼æ¯”"]
                if book_value_per_share > 0 and clean_data["EPS"] > 0:
                    clean_data["ROE"] = round((clean_data["EPS"] / book_value_per_share) * 100, 2)
        except Exception:
            pass
    
    # æª¢æŸ¥æ•¸æ“šå®Œæ•´æ€§
    missing_fields = []
    for key, value in clean_data.items():
        if key not in ["è‚¡ç¥¨ä»£è™Ÿ", "å…¬å¸åç¨±"] and value == 0:
            missing_fields.append(key)
    
    # æª¢æŸ¥è³‡æ–™æ˜¯å¦æœ‰ç•°å¸¸
    critical_fields = ["ç¨…å¾Œæ·¨åˆ©", "EPS", "ROE", "æ”¶ç›¤åƒ¹"]
    has_critical_errors = False
    for key in critical_fields:
        if clean_data[key] <= 0:
            has_critical_errors = True
            break
    
    clean_data["missing_fields"] = missing_fields
    clean_data["has_critical_errors"] = has_critical_errors
    
    return clean_data

def analyze_with_ai(financial_data, analysis_focus=None):
    """ä½¿ç”¨ Gemini AI é€²è¡Œè²¡å‹™æ•¸æ“šåˆ†æ"""
    if not financial_data:
        return "ç„¡æ³•å–å¾—æ­¤è‚¡ç¥¨æ•¸æ“šï¼Œè«‹ç¢ºèªè‚¡ç¥¨ä»£è™Ÿæ˜¯å¦æ­£ç¢ºã€‚"
    
    # å¾è²¡å‹™æ•¸æ“šä¸­æå–è³‡è¨Š
    clean_data = financial_data.copy()
    missing_fields = clean_data.pop("missing_fields")
    has_critical_errors = clean_data.pop("has_critical_errors")
    
    # æ ¹æ“šä½¿ç”¨è€…é¸æ“‡çš„åˆ†æé‡é»èª¿æ•´æç¤ºè©
    focus_prompts = {
        "ç²åˆ©": "è«‹è‘—é‡åˆ†æå…¬å¸çš„ç²åˆ©èƒ½åŠ›ã€ROEå’ŒEPSè¶¨å‹¢ï¼Œè©•ä¼°å…¬å¸çš„ç›ˆåˆ©å“è³ªå’ŒæŒçºŒæ€§ã€‚",
        "é¢¨éšª": "è«‹è©³ç´°è©•ä¼°æŠ•è³‡é¢¨éšªï¼ŒåŒ…æ‹¬ä¼°å€¼é¢¨éšªã€ç”¢æ¥­é¢¨éšªã€è²¡å‹™é¢¨éšªå’Œåœ°ç·£æ”¿æ²»é¢¨éšªã€‚ç‰¹åˆ¥é—œæ³¨æœ¬ç›Šæ¯”å’Œè‚¡åƒ¹æ·¨å€¼æ¯”æ˜¯å¦åˆç†ã€‚",
        "æˆé•·": "è«‹åˆ†æå…¬å¸çš„æˆé•·æ½›åŠ›ã€æœªä¾†ç™¼å±•æ©Ÿæœƒå’Œç”¢æ¥­è¶¨å‹¢ã€‚è©•ä¼°å…¬å¸çš„ç«¶çˆ­å„ªå‹¢å’Œå¸‚å ´æ“´å¼µèƒ½åŠ›ã€‚",
        "è‚¡åˆ©": "è«‹è‘—é‡åˆ†æå…¬å¸çš„è‚¡åˆ©æ”¿ç­–ã€æ®–åˆ©ç‡è¡¨ç¾å’Œè‚¡åˆ©ç™¼æ”¾ç©©å®šæ€§ã€‚è©•ä¼°è‚¡åˆ©æˆé•·æ½›åŠ›å’Œå¯æŒçºŒæ€§ã€‚",
        "ç©æ¥µæŠ•è³‡": "è«‹ä»¥ç©æ¥µæŠ•è³‡è€…çš„è¦–è§’åˆ†æï¼Œè‘—é‡æ–¼æˆé•·æ©Ÿæœƒã€å¸‚å ´æ“´å¼µæ½›åŠ›å’Œå¯èƒ½çš„è‚¡åƒ¹å‚¬åŒ–åŠ‘ã€‚å¿½ç•¥çŸ­æœŸæ³¢å‹•é¢¨éšªï¼Œå°ˆæ³¨æ–¼é•·æœŸé«˜å›å ±å¯èƒ½æ€§ã€‚æä¾›æ›´é€²å–çš„æŠ•è³‡å»ºè­°å’Œæ™‚æ©Ÿé»åˆ¤æ–·ã€‚"
    }
    
    # è¨­å®šåˆ†æé‡é»
    focus_instruction = ""
    if analysis_focus and analysis_focus in focus_prompts:
        focus_instruction = focus_prompts[analysis_focus]
    
    # æ§‹å»º AI è§£ææç¤ºè©
    market_summary = f"""
    # è²¡å‹™åˆ†æè«‹æ±‚
    
    ## å…¬å¸åŸºæœ¬è³‡æ–™
    - å…¬å¸: {clean_data['å…¬å¸åç¨±']} ({clean_data['è‚¡ç¥¨ä»£è™Ÿ']})
    
    ## è²¡å‹™æ•¸æ“šæ‘˜è¦
    - ç‡Ÿæ¥­é¡: {clean_data['ç‡Ÿæ¥­é¡']:,.1f} å…ƒ
    - ç¨…å¾Œæ·¨åˆ©: {clean_data['ç¨…å¾Œæ·¨åˆ©']:,.1f} å…ƒ
    - æ¯è‚¡ç›ˆé¤˜ (EPS): {clean_data['EPS']:.1f}
    - è‚¡æ±æ¬Šç›Šå ±é…¬ç‡ (ROE): {clean_data['ROE']:.1f}%
    - æœ¬ç›Šæ¯” (P/E Ratio): {clean_data['æœ¬ç›Šæ¯”']:.1f}
    - æ®–åˆ©ç‡ (Dividend Yield): {clean_data['æ®–åˆ©ç‡']:.1f}%
    - è‚¡åƒ¹æ·¨å€¼æ¯” (P/B Ratio): {clean_data['è‚¡åƒ¹æ·¨å€¼æ¯”']:.1f}
    - æ”¶ç›¤åƒ¹: {clean_data['æ”¶ç›¤åƒ¹']:,.2f} å…ƒ
    - æœˆå‡åƒ¹: {clean_data['æœˆå‡åƒ¹']:,.2f} å…ƒ
    
    {f"âš ï¸ æ³¨æ„ï¼šä»¥ä¸‹é—œéµè²¡å‹™æ•¸æ“šç¼ºå¤±æˆ–ç•°å¸¸: {', '.join(missing_fields)}" if missing_fields else ""}
    {f"âš ï¸ è­¦å‘Šï¼šéƒ¨åˆ†é—œéµè²¡å‹™æ•¸æ“šï¼ˆå¦‚ç¨…å¾Œæ·¨åˆ©ã€EPSã€ROEæˆ–æ”¶ç›¤åƒ¹ï¼‰ç‚ºé›¶æˆ–ç•°å¸¸ï¼Œåˆ†æçµæœå¯èƒ½ä¸æº–ç¢ºã€‚" if has_critical_errors else ""}
    
    ## åˆ†æé‡é»
    {focus_instruction if focus_instruction else "è«‹å…¨é¢åˆ†æå…¬å¸è²¡å‹™ç‹€æ³ã€æŠ•è³‡åƒ¹å€¼å’Œé¢¨éšªã€‚"}
    
    ## åˆ†æè¦æ±‚
    1. è«‹ä»¥ç¹é«”ä¸­æ–‡å›è¦†
    2. è«‹æä¾›çµæ§‹åŒ–åˆ†æå ±å‘Šï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š
       - å„ªå‹¢åˆ†æ
       - æ½›åœ¨é¢¨éšªå’Œéœ€æ³¨æ„çš„é»
       - æœªä¾†è¶¨å‹¢èˆ‡æŠ•è³‡å»ºè­°
       - ç¸½çµ
    3. ä½¿ç”¨è¡¨æƒ…ç¬¦è™Ÿå¢åŠ å¯è®€æ€§
    4. å¦‚æœæ•¸æ“šå­˜åœ¨ç•°å¸¸æˆ–ç¼ºå¤±ï¼Œè«‹åœ¨åˆ†æä¸­æŒ‡å‡ºä¸¦è§£é‡‹å¯èƒ½çš„å½±éŸ¿
    5. è«‹å®¢è§€åˆ†æï¼Œé¿å…éåº¦æ¨‚è§€æˆ–æ‚²è§€çš„åè¦‹
    """
    
    try:
        # é¡¯ç¤ºåˆ†æä¸­çš„æç¤º
        with st.spinner('AI æ­£åœ¨åˆ†æè²¡å‹™æ•¸æ“šï¼Œè«‹ç¨å€™...'):
            # ç›´æ¥ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹
            model_name = "models/gemini-1.5-pro-latest"
            model = genai.GenerativeModel(model_name)
            
            # è¨­å®šç”Ÿæˆåƒæ•¸
            generation_config = {
                "temperature": 0.2,  # è¼ƒä½çš„æº«åº¦ä½¿è¼¸å‡ºæ›´åŠ ç¢ºå®šæ€§
                "top_p": 0.95,
                "top_k": 40,
                "max_output_tokens": 2048,
            }
            
            # ç”Ÿæˆå…§å®¹
            response = model.generate_content(
                market_summary,
                generation_config=generation_config
            )
            
            return response.text

    except Exception as e:
        return f"AI åˆ†æç™¼ç”ŸéŒ¯èª¤: {str(e)}"

def display_welcome():
    """é¡¯ç¤ºæ­¡è¿è¨Šæ¯å’Œä½¿ç”¨èªªæ˜"""
    st.title("ğŸ“Š å°è‚¡ AI åˆ†æå·¥å…·")
    
    st.markdown("""
    ### ğŸ‘‹ æ­¡è¿ä½¿ç”¨å°è‚¡ AI åˆ†æå·¥å…·ï¼

    é€™å€‹å·¥å…·èƒ½å¹«åŠ©æ‚¨å¿«é€Ÿåˆ†æå°ç£ä¸Šå¸‚å…¬å¸çš„è²¡å‹™ç‹€æ³ï¼Œä¸¦æä¾› AI ç”Ÿæˆçš„æŠ•è³‡å»ºè­°ã€‚

    #### ğŸ“ ä½¿ç”¨æ–¹æ³•ï¼š
    1. åœ¨ä¸‹æ–¹è¼¸å…¥æ¡†ä¸­è¼¸å…¥è‚¡ç¥¨ä»£è™Ÿï¼ˆä¾‹å¦‚ï¼š2330ï¼‰
    2. é¸æ“‡æ‚¨å¸Œæœ›çš„åˆ†æé‡é»
    3. é»æ“Šã€Œåˆ†æã€æŒ‰éˆ•
    4. æŸ¥çœ‹ AI ç”Ÿæˆçš„åˆ†æå ±å‘Š

    #### âœ¨ åŠŸèƒ½ç‰¹é»ï¼š
    - è‡ªå‹•æ“·å–æœ€æ–°è²¡å‹™æ•¸æ“š
    - å¤šç¨®åˆ†æé‡é»å¯é¸
    - AI æ™ºèƒ½åˆ†ææŠ•è³‡åƒ¹å€¼
    - çµæ§‹åŒ–å ±å‘Šä¸€ç›®äº†ç„¶

    #### âš ï¸ æ³¨æ„äº‹é …ï¼š
    - åˆ†æçµæœåƒ…ä¾›åƒè€ƒï¼Œä¸æ§‹æˆæŠ•è³‡å»ºè­°
    - éƒ¨åˆ†è‚¡ç¥¨å¯èƒ½å› æ•¸æ“šç¼ºå¤±è€Œç„¡æ³•å®Œæ•´åˆ†æ
    - è«‹è‡ªè¡Œåˆ¤æ–·æŠ•è³‡é¢¨éšª
    """)

def main():
    """ä¸»å‡½æ•¸ï¼Œè™•ç†æ•´å€‹åˆ†ææµç¨‹"""
    # é¡¯ç¤ºæ­¡è¿è¨Šæ¯
    display_welcome()
    
    # å´é‚Šæ¬„ - åˆ†æé¸é …
    st.sidebar.title("åˆ†æé¸é …")
    analysis_focus = st.sidebar.radio(
        "é¸æ“‡åˆ†æé‡é»ï¼š",
        ["å…¨é¢åˆ†æ", "ç²åˆ©", "é¢¨éšª", "æˆé•·", "è‚¡åˆ©", "ç©æ¥µæŠ•è³‡"],
        index=0
    )
    
    # å°‡é¸é …æ˜ å°„åˆ°APIåƒæ•¸
    focus_mapping = {
        "å…¨é¢åˆ†æ": None,
        "ç²åˆ©": "ç²åˆ©",
        "é¢¨éšª": "é¢¨éšª",
        "æˆé•·": "æˆé•·",
        "è‚¡åˆ©": "è‚¡åˆ©",
        "ç©æ¥µæŠ•è³‡": "ç©æ¥µæŠ•è³‡"
    }
    
    # ä¸»ç•«é¢ - è‚¡ç¥¨æŸ¥è©¢
    with st.form("stock_analysis_form"):
        stock_id = st.text_input("è«‹è¼¸å…¥è‚¡ç¥¨ä»£è™Ÿï¼š", placeholder="ä¾‹å¦‚ï¼š2330")
        submit_button = st.form_submit_button("åˆ†æ")
    
    # ç•¶ä½¿ç”¨è€…æäº¤æŸ¥è©¢
    if submit_button and stock_id:
        # æ¸…é™¤è‚¡ç¥¨ä»£è™Ÿä¸­çš„ç©ºç™½å­—å…ƒ
        stock_id = stock_id.strip()
        
        # é¡¯ç¤ºè™•ç†ä¸­çš„æç¤º
        with st.spinner('æ­£åœ¨æ“·å–è²¡å‹™æ•¸æ“š...'):
            # æ“·å–æ•¸æ“š
            data_frames = fetch_data(stock_id)
            
            if not data_frames:
                st.error("ç„¡æ³•å–å¾—æ•¸æ“šï¼Œè«‹ç¢ºèªè‚¡ç¥¨ä»£è™Ÿæ˜¯å¦æ­£ç¢ºã€‚")
                return
            
            # åˆä½µæ•¸æ“š
            merged_df = merge_data(data_frames)
            
            if merged_df.empty:
                st.error("åˆä½µæ•¸æ“šå¤±æ•—ï¼Œè«‹ç¢ºèªè‚¡ç¥¨ä»£è™Ÿæ˜¯å¦æ­£ç¢ºã€‚")
                return
            
            # æå–è²¡å‹™æ•¸æ“š
            financial_data = extract_financial_data(merged_df, stock_id)
            
            if not financial_data:
                st.error("ç„¡æ³•æå–è²¡å‹™æ•¸æ“šï¼Œè«‹ç¢ºèªè‚¡ç¥¨ä»£è™Ÿæ˜¯å¦æ­£ç¢ºã€‚")
                return
        
        # é¡¯ç¤ºè²¡å‹™æ•¸æ“šæ‘˜è¦
        st.subheader("ğŸ“Š è²¡å‹™æ•¸æ“šæ‘˜è¦")
        
        # ä½¿ç”¨å…©æ¬„ä½ˆå±€é¡¯ç¤ºè²¡å‹™æ•¸æ“š
        col1, col2 = st.columns(2)
        
        with col1:
            st.info(f"**å…¬å¸**: {financial_data['å…¬å¸åç¨±']} ({financial_data['è‚¡ç¥¨ä»£è™Ÿ']})")
            st.metric("ç‡Ÿæ¥­é¡", f"{financial_data['ç‡Ÿæ¥­é¡']:,.1f} å…ƒ")
            st.metric("ç¨…å¾Œæ·¨åˆ©", f"{financial_data['ç¨…å¾Œæ·¨åˆ©']:,.1f} å…ƒ")
            st.metric("æ¯è‚¡ç›ˆé¤˜ (EPS)", f"{financial_data['EPS']:.1f}")
            st.metric("è‚¡æ±æ¬Šç›Šå ±é…¬ç‡ (ROE)", f"{financial_data['ROE']:.1f}%")
        
        with col2:
            st.metric("æœ¬ç›Šæ¯” (P/E Ratio)", f"{financial_data['æœ¬ç›Šæ¯”']:.1f}")
            st.metric("æ®–åˆ©ç‡ (Dividend Yield)", f"{financial_data['æ®–åˆ©ç‡']:.1f}%")
            st.metric("è‚¡åƒ¹æ·¨å€¼æ¯” (P/B Ratio)", f"{financial_data['è‚¡åƒ¹æ·¨å€¼æ¯”']:.1f}")
            st.metric("æ”¶ç›¤åƒ¹", f"{financial_data['æ”¶ç›¤åƒ¹']:,.2f} å…ƒ")
            st.metric("æœˆå‡åƒ¹", f"{financial_data['æœˆå‡åƒ¹']:,.2f} å…ƒ")
        
        # é¡¯ç¤ºè­¦å‘Šè¨Šæ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if financial_data["missing_fields"]:
            st.warning(f"âš ï¸ æ³¨æ„ï¼šä»¥ä¸‹é—œéµè²¡å‹™æ•¸æ“šç¼ºå¤±æˆ–ç•°å¸¸: {', '.join(financial_data['missing_fields'])}")
        
        if financial_data["has_critical_errors"]:
            st.error("âš ï¸ è­¦å‘Šï¼šéƒ¨åˆ†é—œéµè²¡å‹™æ•¸æ“šï¼ˆå¦‚ç¨…å¾Œæ·¨åˆ©ã€EPSã€ROEæˆ–æ”¶ç›¤åƒ¹ï¼‰ç‚ºé›¶æˆ–ç•°å¸¸ï¼Œåˆ†æçµæœå¯èƒ½ä¸æº–ç¢ºã€‚")
        
        # åŸ·è¡Œ AI åˆ†æ
        analysis_result = analyze_with_ai(financial_data, focus_mapping[analysis_focus])
        
        # é¡¯ç¤ºåˆ†æçµæœ
        st.subheader("ğŸ“ AI åˆ†æå ±å‘Š")
        st.markdown(analysis_result)
        
        # æä¾›ä¸‹è¼‰æ•¸æ“šçš„é¸é …
        csv = merged_df.to_csv(index=False)
        st.download_button(
            label="ä¸‹è¼‰è²¡å‹™æ•¸æ“š (CSV)",
            data=csv,
            file_name=f"stock_analysis_{stock_id}.csv",
            mime="text/csv",
        )
    
    # é¡¯ç¤ºé è…³
    st.markdown("---")
    st.markdown("### ğŸ“Œ æç¤º")
    st.info("æ‚¨å¯ä»¥éš¨æ™‚è¼¸å…¥æ–°çš„è‚¡ç¥¨ä»£è™Ÿé€²è¡Œåˆ†æã€‚é—œé–‰ç€è¦½å™¨è¦–çª—å³å¯çµæŸä½¿ç”¨ã€‚")
    st.markdown("Â© 2025 å°è‚¡ AI åˆ†æå·¥å…· | è³‡æ–™ä¾†æº: å°ç£è­‰åˆ¸äº¤æ˜“æ‰€")

if __name__ == "__main__":
    main()
